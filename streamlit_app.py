import streamlit as st
import requests
import time
import re
import random
import os
import pandas as pd
import concurrent.futures
import statistics
from datetime import datetime

# ===========================
# 1. é¡µé¢é…ç½®
# ===========================
st.set_page_config(page_title="VLESS å…¨èƒ½è¯„æµ‹å®¤", page_icon="ğŸ§ª", layout="wide")

st.markdown("""
    <style>
    .stApp { background-color: #0E1117; color: #FAFAFA; }
    div[data-testid="column"] { background-color: #1E1E1E; border: 1px solid #333; border-radius: 8px; padding: 15px; }
    /* è¿›åº¦æ¡é¢œè‰² */
    .stProgress > div > div > div > div { background-color: #00FF99; }
    </style>
    """, unsafe_allow_html=True)

# ===========================
# 2. é…ç½®è¯»å–
# ===========================
try:
    CF_CONFIG = {
        "api_token": st.secrets["api_token"].strip(),
        "zone_id": st.secrets["zone_id"].strip(),
        "record_name": st.secrets["record_name"].strip(),
    }
except:
    st.error("âŒ é…ç½®ç¼ºå¤±ï¼è¯·æ£€æŸ¥ secrets.toml")
    st.stop()

DB_FILE = "scan_history.log"

# ===========================
# 3. åŸºç¡€å·¥å…·å‡½æ•°
# ===========================

@st.cache_data(ttl=3600)
def get_ip_info(ip):
    try:
        url = f"http://ip-api.com/json/{ip}?fields=countryCode,country"
        r = requests.get(url, timeout=2).json()
        cc = r.get("countryCode", "UNK")
        if cc in ['CN', 'HK', 'TW', 'JP', 'KR', 'SG']: return "ğŸŒ äºšæ´²", r.get("country")
        if cc in ['US', 'CA', 'MX']: return "ğŸ‡ºğŸ‡¸ ç¾æ´²", r.get("country")
        if cc in ['DE', 'GB', 'FR', 'NL']: return "ğŸ‡ªğŸ‡º æ¬§æ´²", r.get("country")
        return "ğŸŒ å…¶ä»–", r.get("country")
    except:
        return "ğŸ›¸ æœªçŸ¥", "Unknown"

def get_collected_ips():
    """è·å– IP æ±  (å«å®˜æ–¹æºä¿åº•)"""
    sources = [
        "https://www.cloudflare.com/ips-v4", # å®˜æ–¹æº
        "https://raw.githubusercontent.com/Alvin9999/new-pac/master/cloudflare.txt",
        "https://raw.githubusercontent.com/w8ves/CF-IP/master/speedtest.txt"
    ]
    all_ips = set()
    
    def fetch(url):
        try:
            r = requests.get(url, timeout=4)
            return re.findall(r'(?:\d{1,3}\.){3}\d{1,3}', r.text)
        except: return []

    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as ex:
        for res in ex.map(fetch, sources): all_ips.update(res)
    
    # æ‰©å¤§æ ·æœ¬é‡åˆ° 80 ä¸ªä»¥å¢åŠ å‘½ä¸­ç‡
    final_list = list(all_ips)
    return random.sample(final_list, min(len(final_list), 80))

# ===========================
# 4. æ·±åº¦æµ‹è¯•æ ¸å¿ƒé€»è¾‘
# ===========================

def basic_ping(ip):
    """åˆç­›ï¼šå•æ¬¡ Ping"""
    try:
        start = time.time()
        requests.head(f"http://{ip}", headers={"Host": CF_CONFIG['record_name']}, timeout=1.0)
        return int((time.time() - start) * 1000)
    except: return 9999

def advanced_test(node):
    """ç²¾æµ‹ï¼šæŠ–åŠ¨ã€ä¸¢åŒ…ã€é€Ÿåº¦ã€è§£é”"""
    ip = node['ip']
    
    # 1. ä¸¢åŒ…ä¸æŠ–åŠ¨æµ‹è¯• (Ping 5æ¬¡)
    delays = []
    loss_count = 0
    for _ in range(5):
        try:
            s = time.time()
            requests.head(f"http://{ip}", headers={"Host": CF_CONFIG['record_name']}, timeout=1.5)
            delays.append((time.time() - s) * 1000)
        except:
            loss_count += 1
            
    # è®¡ç®—ç¨³å®šæ€§æŒ‡æ ‡
    loss_rate = (loss_count / 5) * 100
    avg_lat = statistics.mean(delays) if delays else 9999
    jitter = int(statistics.stdev(delays)) if len(delays) > 1 else 0
    
    # 2. é€Ÿåº¦æµ‹è¯• (ä¸‹è½½ 1MB å°æ–‡ä»¶)
    speed_mb = 0.0
    try:
        # ä½¿ç”¨ CF å®˜æ–¹æµ‹é€Ÿç‚¹ï¼Œæ¨¡æ‹ŸçœŸå®å›æº
        s_time = time.time()
        # ä¸‹è½½ 1MB æ•°æ®
        r = requests.get(f"http://{ip}/__down?bytes=1000000", headers={"Host": "speed.cloudflare.com"}, timeout=5, stream=True)
        size = 0
        for chunk in r.iter_content(chunk_size=1024):
            size += len(chunk)
            if size >= 1000000: break
        duration = time.time() - s_time
        if duration > 0:
            speed_mb = (size / 1024 / 1024) / duration # MB/s
    except:
        speed_mb = 0.0

    # 3. æµåª’ä½“è§£é” (Netflix + YouTube)
    nf_status = "â“"
    yt_status = "â“"
    try:
        # Netflix
        r_nf = requests.get(f"http://{ip}/title/80018499", headers={"Host": "www.netflix.com"}, timeout=2)
        nf_status = "âœ…" if r_nf.status_code in [200, 301, 302] else "âŒ"
        # YouTube (ç®€å•æ£€æµ‹)
        r_yt = requests.get(f"http://{ip}", headers={"Host": "www.youtube.com"}, timeout=2)
        yt_status = "âœ…" if r_yt.status_code == 200 else "âŒ"
    except: pass

    return {
        "ip": ip,
        "source": node['source'],
        "region": node['region'],
        "country": node['country'],
        "lat": int(avg_lat),      # å¹³å‡å»¶è¿Ÿ
        "jitter": jitter,         # æŠ–åŠ¨
        "loss": f"{int(loss_rate)}%", # ä¸¢åŒ…
        "speed": f"{speed_mb:.2f}",   # é€Ÿåº¦
        "nf": nf_status,
        "yt": yt_status
    }

def sync_dns(ip):
    url = f"https://api.cloudflare.com/client/v4/zones/{CF_CONFIG['zone_id']}/dns_records"
    headers = {"Authorization": f"Bearer {CF_CONFIG['api_token']}"}
    try:
        params = {"name": CF_CONFIG['record_name'], "type": "A"}
        recs = requests.get(url, headers=headers, params=params, timeout=5).json()
        if not recs.get("result"): return "âŒ æ— è®°å½•"
        
        rid = recs["result"][0]["id"]
        if recs["result"][0]["content"] == ip: return "âœ… IPæœªå˜"
        
        requests.put(f"{url}/{rid}", headers=headers, json={
            "type": "A", "name": CF_CONFIG['record_name'], "content": ip, "ttl": 60, "proxied": False
        })
        return f"ğŸš€ å·²åŒæ­¥: {ip}"
    except Exception as e: return "âš ï¸ APIé”™è¯¯"

# ===========================
# 5. ä¸»ç¨‹åºé€»è¾‘
# ===========================

st.title("ğŸ§ª VLESS å…¨èƒ½è¯„æµ‹å®¤")

col_btn, col_info = st.columns([1, 3])
with col_btn:
    start_btn = st.button("ğŸš€ å¼€å§‹æ·±åº¦ä½“æ£€", type="primary", use_container_width=True)
with col_info:
    st.info("ğŸ’¡ è¯„æµ‹é¡¹ç›®ï¼šå»¶è¿Ÿ(Latency) | æŠ–åŠ¨(Jitter) | ä¸¢åŒ…(Loss) | é€Ÿåº¦(Speed) | è§£é”(Unlock)")

if start_btn:
    
    # --- ç¬¬ä¸€é˜¶æ®µï¼šæµ·é€‰ (å¿«é€Ÿ Ping) ---
    st.subheader("1ï¸âƒ£ ç¬¬ä¸€é˜¶æ®µï¼šå…¨çƒæµ·é€‰ (Broad Scan)")
    status_text = st.empty()
    bar = st.progress(0)
    
    # å‡†å¤‡ IP
    local_ips = ["108.162.194.1", "108.162.192.5", "172.64.32.12", "162.159.61.1"]
    collected_ips = get_collected_ips()
    
    # åˆå¹¶ä»»åŠ¡
    tasks = [{"ip": ip, "source": "ğŸ  é¢„è®¾"} for ip in local_ips] + \
            [{"ip": ip, "source": "â˜ï¸ é‡‡é›†"} for ip in collected_ips]
    
    status_text.text(f"æ­£åœ¨å¯¹ {len(tasks)} ä¸ªèŠ‚ç‚¹è¿›è¡Œå¿«é€Ÿ Ping...")
    
    candidates = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=30) as ex:
        future_map = {ex.submit(basic_ping, t['ip']): t for t in tasks}
        done = 0
        for fut in concurrent.futures.as_completed(future_map):
            done += 1
            bar.progress(done / len(tasks))
            lat = fut.result()
            if lat < 1000: # åˆç­›åˆæ ¼çº¿
                node = future_map[fut]
                # é¡ºä¾¿æŸ¥ä¸€ä¸‹åœ°åŒºï¼Œä¸ºç²¾æµ‹åšå‡†å¤‡
                reg, ctry = get_ip_info(node['ip'])
                candidates.append({**node, "lat": lat, "region": reg, "country": ctry})
    
    if not candidates:
        st.error("âŒ ç¬¬ä¸€é˜¶æ®µå…¨å†›è¦†æ²¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œã€‚")
        st.stop()
        
    # é€‰å‡ºå‰ 10 åè¿›å…¥å¤èµ›
    candidates.sort(key=lambda x: x['lat'])
    top_10 = candidates[:10]
    
    st.success(f"âœ… æµ·é€‰ç»“æŸï¼Œ{len(candidates)} ä¸ªèŠ‚ç‚¹åœ¨çº¿ï¼Œå‰ 10 åè¿›å…¥æ·±åº¦ä½“æ£€ã€‚")
    st.divider()
    
    # --- ç¬¬äºŒé˜¶æ®µï¼šç²¾æµ‹ (æ·±åº¦æµ‹è¯•) ---
    st.subheader("2ï¸âƒ£ ç¬¬äºŒé˜¶æ®µï¼šæ·±åº¦ä½“æ£€ (Deep Test)")
    st.caption("æ­£åœ¨è¿›è¡Œï¼š5æ¬¡è¿Pingæµ‹æŠ–åŠ¨/ä¸¢åŒ… + 1MBä¸‹è½½æµ‹é€Ÿ + åª’ä½“è§£é”æ£€æµ‹...")
    
    final_results = []
    bar2 = st.progress(0)
    
    # è¿™é‡Œä¸èƒ½å¹¶å‘å¤ªé«˜ï¼Œé˜²æ­¢æµ‹é€ŸæŠ¢å¸¦å®½å¯¼è‡´ç»“æœä¸å‡†
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as ex:
        futs = [ex.submit(advanced_test, node) for node in top_10]
        for i, fut in enumerate(concurrent.futures.as_completed(futs)):
            bar2.progress((i + 1) / len(top_10))
            final_results.append(fut.result())
            
    # --- ç»“æœå±•ç¤º ---
    # ç»¼åˆæ’åºï¼šä¼˜å…ˆçœ‹ä¸¢åŒ…(Loss)ï¼Œå…¶æ¬¡çœ‹å»¶è¿Ÿ(Lat)ï¼Œæœ€åçœ‹é€Ÿåº¦(Speed å€’åºï¼Œå¤§çš„å¥½)
    # è¿™é‡Œç®€å•å¤„ç†ï¼šæŒ‰å»¶è¿Ÿæ’
    final_results.sort(key=lambda x: x['lat'])
    winner = final_results[0]
    
    # åŒæ­¥ DNS
    sync_msg = sync_dns(winner['ip'])
    
    # å† å†›å±•ç¤º
    c1, c2, c3, c4 = st.columns(4)
    with c1: st.metric("ğŸ† ä¼˜é€‰ IP", winner['ip'])
    with c2: st.metric("å¹³å‡å»¶è¿Ÿ", f"{winner['lat']} ms", f"æŠ–åŠ¨ Â±{winner['jitter']}")
    with c3: st.metric("ä¸‹è½½é€Ÿåº¦", f"{winner['speed']} MB/s")
    with c4: st.metric("ä¸¢åŒ…ç‡", winner['loss'], delta_color="inverse")
    
    st.info(f"ğŸ“ {sync_msg}")
    
    # è¯¦ç»†è¡¨æ ¼
    df = pd.DataFrame(final_results)
    
    # é‡å‘½ååˆ—ä»¥æ˜¾ç¤ºæ›´å¥½çœ‹
    st.dataframe(
        df[["source", "ip", "region", "country", "lat", "jitter", "loss", "speed", "nf", "yt"]].rename(columns={
            "source": "æ¥æº", "ip": "IP", "region": "åŒºåŸŸ", "country": "å›½å®¶",
            "lat": "å»¶è¿Ÿ(ms)", "jitter": "æŠ–åŠ¨", "loss": "ä¸¢åŒ…", "speed": "é€Ÿåº¦(MB/s)",
            "nf": "Netflix", "yt": "YouTube"
        }),
        use_container_width=True,
        hide_index=True
    )
    
    # å†™å…¥æ—¥å¿—
    with open(DB_FILE, "a") as f:
        f.write(f"{datetime.now().strftime('%H:%M')} | {winner['ip']} | {winner['lat']}ms | Speed:{winner['speed']}MB/s\n")

# å†å²è®°å½•
with st.expander("ğŸ“œ æŸ¥çœ‹å†å²è®°å½•"):
    if os.path.exists(DB_FILE):
        with open(DB_FILE, "r") as f: st.text("".join(f.readlines()[-5:]))
